import os
from dotenv import load_dotenv
from langchain.vectorstores import Chroma
from langchain.embeddings.openai import OpenAIEmbeddings
from langchain_community.chat_models import ChatOpenAI
from langchain_community.chat_message_histories import ChatMessageHistory

load_dotenv()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

def initialize_chroma_db(persist_directory: str) -> Chroma:
    """
    Chroma DBë¥¼ ì´ˆê¸°í™”í•˜ì—¬ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)
    return Chroma(
        persist_directory=persist_directory,
        embedding_function=embeddings
    )


def fetch_data(retriever, query: str, max_docs: int = 3) -> list:
    """
    retriever.invoke(query) ê²°ê³¼ì—ì„œ ìµœëŒ€ max_docsê°œì˜ ë¬¸ì„œë§Œ ì¶”ì¶œ,
    ê° ë¬¸ì„œì˜ page_contentë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜
    """

    if not isinstance(query, str):
        print(f"ğŸš¨ ì˜¤ë¥˜ ë°œìƒ! query íƒ€ì…: {type(query)}, ê°’: {query}")
        return []
    
    docs = retriever.invoke(query)
    results = []
    for i, doc in enumerate(docs):
        if i >= max_docs:
            break
        results.append(doc.page_content)
    return results

def initialize_retriever(db, k: int = 3):
    """
    Chroma DBë¡œë¶€í„° Retrieverë¥¼ ìƒì„±í•˜ì—¬ ë°˜í™˜í•©ë‹ˆë‹¤.
    - search_type="similarity_score_threshold"
    - score_threshold=0.8
    """
    return db.as_retriever(
        search_type="similarity_score_threshold",
        search_kwargs={"score_threshold": 0.8}
    )

def initialize_llm(model_name: str = "gpt-4o", temperature: float = 0):
    """
    ChatOpenAI ëª¨ë¸ì„ ì´ˆê¸°í™”í•˜ê³  ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    return ChatOpenAI(
        model=model_name,
        temperature=temperature,
        openai_api_key=OPENAI_API_KEY
    )
