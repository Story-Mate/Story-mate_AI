import os
import pymysql
from dotenv import load_dotenv

# .env íŒŒì¼ ë¡œë“œ
load_dotenv()

# í™˜ê²½ ë³€ìˆ˜ ê°€ì ¸ì˜¤ê¸°
DB_HOST = os.getenv("DB_HOST")
DB_USER = os.getenv("DB_USER")
DB_PASSWORD = os.getenv("DB_PASSWORD")
DB_NAME = os.getenv("DB_NAME")
DB_CHARSET = os.getenv("DB_CHARSET", "utf8mb4")  # ê¸°ë³¸ê°’ utf8mb4

# MariaDB ì—°ê²° í•¨ìˆ˜
def get_db_connection():
    return pymysql.connect(
        host=DB_HOST,
        user=DB_USER,
        password=DB_PASSWORD,
        database=DB_NAME,
        charset=DB_CHARSET,
        cursorclass=pymysql.cursors.DictCursor
    )


from langchain_core.output_parsers import StrOutputParser
from langchain_core.prompts import ChatPromptTemplate

# ëª¨ë“ˆì—ì„œ í•„ìš”í•œ í•¨ìˆ˜ë“¤ì„ ì„í¬íŠ¸
from utils import (
    initialize_chroma_db, fetch_data, initialize_retriever, initialize_llm
)
from template import get_character_template

OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")




class ChatBot:

    # âœ… ChatBot í´ë˜ìŠ¤ ì´ˆê¸°í™”
    def __init__(self, character_name, book_title):
        # 2) DB ê²½ë¡œ ì„¤ì •
        base_path = f"{book_title}/{character_name}/data/embedding"
        self.character_name = character_name
        self.book_title = book_title
        # 3) DB & ë¦¬íŠ¸ë¦¬ë²„ ì´ˆê¸°í™”
        self.q_db = initialize_chroma_db(f"{base_path}/ì˜ˆìƒì§ˆë¬¸_chroma_db")
        self.e_db = initialize_chroma_db(f"{base_path}/ì¸ë¬¼í‰ê°€_chroma_db")
        self.n_db = initialize_chroma_db(f"{base_path}/ì „ë¬¸_chroma_db")
        self.c_db = initialize_chroma_db(f"{base_path}/ì¸ë¬¼íŠ¹ì„±_chroma_db")

        self.q_retriever = initialize_retriever(self.q_db)
        self.e_retriever = initialize_retriever(self.e_db)
        self.n_retriever = initialize_retriever(self.n_db)
        self.c_retriever = initialize_retriever(self.c_db)

        # 4) í…œí”Œë¦¿ & LLM
        self.prompt_template = get_character_template(book_title, character_name)
        self.llm = initialize_llm(model_name="gpt-4o")

        # 5) ì²´ì¸ ê²°í•© (PromptTemplate â†’ LLM â†’ StrOutputParser)
        self.chain = self.prompt_template | self.llm | StrOutputParser()




    # âœ… DBì—ì„œ ëŒ€í™” ê¸°ë¡ ë¶ˆëŸ¬ì˜¤ê¸°
    def load_chat_history(self, session_id):
        """
        íŠ¹ì • session_idì˜ ëŒ€í™” ê¸°ë¡ì„ MariaDBì—ì„œ ë¶ˆëŸ¬ì˜´
        """
        conn = get_db_connection()
        cursor = conn.cursor()
        cursor.execute("SELECT role, content FROM conversations WHERE session_id = %s ORDER BY created_at", (session_id,))
        messages = cursor.fetchall()
        conn.close()
        return messages



    # âœ… DBì— ëŒ€í™” ê¸°ë¡ ì €ì¥
    def save_chat_history(self, session_id, role, content):
        """
        MariaDBì— ìƒˆë¡œìš´ ëŒ€í™” ë‚´ìš©ì„ ì €ì¥
        """
        conn = get_db_connection()
        cursor = conn.cursor()
        cursor.execute(
            "INSERT INTO conversations (session_id, role, content) VALUES (%s, %s, %s)",
            (session_id, role, content)
        )
        conn.commit()
        conn.close()



    # âœ… ìƒˆë¡œìš´ ëŒ€í™” ì¶”ê°€ (ì‚¬ìš©ì â†’ ì±—ë´‡)
    def add_conversation(self, session_id, user_query, response):
        """
        ìƒˆë¡œìš´ ëŒ€í™”ë¥¼ MariaDBì— ì €ì¥
        """
        self.save_chat_history(session_id, "human", user_query)
        self.save_chat_history(session_id, "ai", response)



    # âœ… ëŒ€í™” ë‚´ìš©ì„ ìš”ì•½í•˜ëŠ” í•¨ìˆ˜
    def summarize_history(self, session_id):
        """
        íŠ¹ì • ì„¸ì…˜ì˜ ëŒ€í™” ê¸°ë¡ì„ MariaDBì—ì„œ ë¶ˆëŸ¬ì™€ ìš”ì•½í•˜ëŠ” í•¨ìˆ˜
        """

        history = self.load_chat_history(session_id)


        if not history:
            return "ì´ì „ ëŒ€í™” ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤."

        # ìš”ì•½í•  í…ìŠ¤íŠ¸ ë³€í™˜ (roleì„ ë¶™ì—¬ì„œ ì •ë¦¬)
        conversation_text = "\n".join(
            [f"{'ì‚¬ìš©ì' if msg['role'] == 'human' else self.character_name}: {msg['content']}" for msg in history]
        )

        # ìš”ì•½ í”„ë¡¬í”„íŠ¸ ì„¤ì •
        summary_prompt = (
        """
        [ì´ì „ ëŒ€í™” ìš”ì•½]
        - ë§ˆí¬ë‹¤ìš´ í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•©ë‹ˆë‹¤.
        - ì‚¬ìš©ìì˜ ì •ë³´ì™€ ëŒ€í™” ì£¼ì œë¥¼ ê°•ì¡°í•˜ì—¬ chat_historyë¥¼ ìš”ì•½í•©ë‹ˆë‹¤.

        chat_history : {conversation_text}"""
        )

        # ìš”ì•½ ì‹¤í–‰
        summary_chain = ChatPromptTemplate.from_template(summary_prompt) | self.llm | StrOutputParser()
        summary = summary_chain.invoke({"conversation_text": conversation_text})

        print(f"[ëŒ€í™” ìš”ì•½]: {summary}")
        return summary 



    # âœ… ìµœì¢… ë‹µë³€ ìƒì„± í•¨ìˆ˜
    def get_answer(self, session_id: str, user_query: str) -> str:
        """
        ì„¸ì…˜ ID ê¸°ë°˜ìœ¼ë¡œ DB ê²€ìƒ‰ í›„, ìºë¦­í„° í…œí”Œë¦¿ê³¼ LLMìœ¼ë¡œ ë‹µë³€ ìƒì„±
            """
        
        if not isinstance(user_query, str) or not user_query.strip():
            return "ì˜¤ë¥˜: ì§ˆë¬¸ì´ ì—†ìŠµë‹ˆë‹¤."

        print(f"ğŸ“Œ get_answer()ì—ì„œ user_query í™•ì¸: {user_query} (type: {type(user_query)})")
        
        # ê° DBì—ì„œ contextë¥¼ ê²€ìƒ‰
        question_context  = fetch_data(self.q_retriever, user_query)
        evaluate_context  = fetch_data(self.e_retriever, user_query)
        novel_context     = fetch_data(self.n_retriever, user_query)
        character_context = fetch_data(self.c_retriever, user_query)

        # ì´ì „ ëŒ€í™” ë‚´ìš© ìš”ì•½
        summarized_history = self.summarize_history(session_id)

        # ì²´ì¸ì— ë„£ì„ input_data
        input_data = {
            "context_doc1": novel_context,
            "context_doc2": evaluate_context,
            "context_doc3": character_context,
            "context_doc4": question_context,
            "query": user_query,
            "chat_history": summarized_history,
        }

        # ì²´ì¸ ì‹¤í–‰
        response = self.chain.invoke(input_data)

        # ëŒ€í™” ì €ì¥
        self.add_conversation(session_id, user_query, response)

        return response